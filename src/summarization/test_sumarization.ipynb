{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c16472",
   "metadata": {},
   "source": [
    "# Pruebas de resumen\n",
    "\n",
    "Ejecuta los resumidores definidos en `src/summarization/summarizer.py` contra los artículos de `data_example/` y guarda los textos resultantes dentro de cada archivo JSON para dejarlos listos para la etapa de recomendación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdf6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artículos detectados: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/ari/Collage/04-Forth_Year/Preimer_Semestre/PL/Final_Proj/Report_Generator\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data_example\"\n",
    "\n",
    "article_paths = sorted(DATA_DIR.glob(\"article_*.json\"))\n",
    "print(f\"Artículos detectados: {len(article_paths)}\")\n",
    "\n",
    "def load_article(path: Path) -> dict:\n",
    "    with open(path, encoding=\"utf-8\") as fh:\n",
    "        return json.load(fh)\n",
    "\n",
    "\n",
    "def persist_article(path: Path, data: dict) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(data, fh, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def update_article(path: Path, updates: dict) -> dict:\n",
    "    data = load_article(path)\n",
    "    data.update(updates)\n",
    "    persist_article(path, data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409b72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from summarizer import TextRankSummarizer, PersonalizedSummarizer\n",
    "\n",
    "base_summarizer = TextRankSummarizer(language=\"spanish\")\n",
    "personalized_summarizer = PersonalizedSummarizer(base_summarizer)\n",
    "\n",
    "summary_results = {}\n",
    "\n",
    "for path in article_paths:\n",
    "    article = load_article(path)\n",
    "    text = article.get(\"text\", \"\")\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    extractive = base_summarizer.summarize(text, num_sentences=3)\n",
    "\n",
    "    tag_categories = [tag.replace(\" \", \"_\") for tag in article.get(\"tags\", [])]\n",
    "    personalized = personalized_summarizer.summarize_for_profile(\n",
    "        text,\n",
    "        user_categories=tag_categories,\n",
    "        num_sentences=3\n",
    "    )\n",
    "\n",
    "    sentence_count = len(sent_tokenize(extractive, language=\"spanish\"))\n",
    "\n",
    "    updates = {\n",
    "        \"summaries\": {\n",
    "            \"extractive\": extractive,\n",
    "            \"personalized\": personalized,\n",
    "            \"sentence_count\": sentence_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "    update_article(path, updates)\n",
    "    summary_results[path.name] = updates[\"summaries\"]\n",
    "\n",
    "pprint(summary_results.get(\"article_1.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b732fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "mock_profile = [\n",
    "    \"crisis_humanitaria\",\n",
    "    \"derechos_humanos\",\n",
    "    \"operacion_militar\",\n",
    "    \"ayuda_refugiados\"\n",
    "]\n",
    "\n",
    "mock_profile_results = {}\n",
    "\n",
    "for path in article_paths:\n",
    "    article = load_article(path)\n",
    "    text = article.get(\"text\", \"\")\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    mock_summary = personalized_summarizer.summarize_for_profile(\n",
    "        text,\n",
    "        user_categories=mock_profile,\n",
    "        num_sentences=2\n",
    "    )\n",
    "\n",
    "    summaries = article.get(\"summaries\", {})\n",
    "    summaries[\"mock_profile\"] = {\n",
    "        \"categories\": mock_profile,\n",
    "        \"summary\": mock_summary\n",
    "    }\n",
    "    update_article(path, {\"summaries\": summaries})\n",
    "\n",
    "    mock_profile_results[path.name] = summaries[\"mock_profile\"]\n",
    "\n",
    "pprint(mock_profile_results.get(\"article_1.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b149b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from summarizer import TextRankSummarizer, PersonalizedSummarizer\n",
    "\n",
    "base_summarizer = TextRankSummarizer(language=\"spanish\")\n",
    "personalized_summarizer = PersonalizedSummarizer(base_summarizer)\n",
    "\n",
    "mock_profile = [\n",
    "    \"crisis_humanitaria\",\n",
    "    \"derechos_humanos\",\n",
    "    \"operacion_militar\",\n",
    "    \"ayuda_refugiados\"\n",
    "]\n",
    "\n",
    "summary_results = {}\n",
    "\n",
    "for path in article_paths:\n",
    "    article = load_article(path)\n",
    "    text = article.get(\"text\", \"\")\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    extractive = base_summarizer.summarize(text, num_sentences=3)\n",
    "\n",
    "    tag_categories = [tag.replace(\" \", \"_\") for tag in article.get(\"tags\", [])]\n",
    "    personalized = personalized_summarizer.summarize_for_profile(\n",
    "        text,\n",
    "        user_categories=mock_profile,\n",
    "        num_sentences=2\n",
    "    )\n",
    "\n",
    "    sentence_count = len(sent_tokenize(extractive, language=\"spanish\"))\n",
    "\n",
    "    updates = {\n",
    "        \"summaries\": {\n",
    "            \"extractive\": extractive,\n",
    "            \"personalized\": personalized,\n",
    "            \"sentence_count\": sentence_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "    update_article(path, updates)\n",
    "    summary_results[path.name] = updates[\"summaries\"]\n",
    "\n",
    "pprint(summary_results.get(\"article_1.json\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "report-generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
